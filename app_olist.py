import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import os
import requests
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '.env'))

def get_naver_api_credentials():
    # Streamlit Cloud (Secrets) ìš°ì„  ìˆœìœ„
    if "naver_api" in st.secrets:
        return st.secrets["naver_api"]["client_id"], st.secrets["naver_api"]["client_secret"]
    
    # ë¡œì»¬ .env í™•ì¸
    client_id = os.getenv("NAVER_CLIENT_ID")
    client_secret = os.getenv("NAVER_CLIENT_SECRET")
    return client_id, client_secret

@st.cache_data
def fetch_naver_trend(keywords, start_date, end_date):
    client_id, client_secret = get_naver_api_credentials()
    if not client_id or not client_secret or "your_client_id" in client_id:
        return None
    
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
        "Content-Type": "application/json"
    }
    
    keyword_groups = [{"groupName": kw, "keywords": [kw]} for kw in keywords if kw.strip()]
    if not keyword_groups:
        return None

    body = {
        "startDate": start_date,
        "endDate": end_date,
        "timeUnit": "month",
        "keywordGroups": keyword_groups
    }
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(body))
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Olist E-commerce ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")

# ë°ì´í„° ê²½ë¡œ ì„¤ì • (ìœ ì—°í•œ ê²½ë¡œ íƒìƒ‰: DATA_1 í´ë” ë˜ëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬)
base_path = os.path.dirname(__file__)
possible_data_paths = [
    os.path.join(base_path, 'DATA_1'),
    os.path.join(base_path, 'data_1'),
    base_path # íŒŒì¼ì´ í´ë” ì—†ì´ ë£¨íŠ¸ì— ìˆëŠ” ê²½ìš°
]

DATA_PATH = None
for p in possible_data_paths:
    # í•„ìˆ˜ íŒŒì¼ ì¤‘ í•˜ë‚˜ì¸ olist_orders_datasetì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ê²½ë¡œ íŒë³„
    if os.path.exists(os.path.join(p, 'olist_orders_dataset.parquet')) or \
       os.path.exists(os.path.join(p, 'olist_orders_dataset.csv')):
        DATA_PATH = p
        break

if not DATA_PATH:
    st.error("âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.write(f"í˜„ì¬ ìœ„ì¹˜({base_path})ì˜ íŒŒì¼ ëª©ë¡:", os.listdir(base_path))
    st.info("ë°ì´í„° íŒŒì¼ë“¤ì„ 'DATA_1' í´ë”ì— ë„£ê±°ë‚˜, app_olist.pyì™€ ê°™ì€ ìœ„ì¹˜ì— ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

@st.cache_data
def load_data():
    # íŒŒì¼ í™•ì¥ì ìš°ì„ ìˆœìœ„ (.parquet -> .csv)
    file_bases = {
        'orders': 'olist_orders_dataset',
        'order_items': 'olist_order_items_dataset',
        'order_reviews': 'olist_order_reviews_dataset',
        'products': 'olist_products_dataset',
        'payments': 'olist_order_payments_dataset',
        'customers': 'olist_customers_dataset',
        'sellers': 'olist_sellers_dataset',
        'translation': 'product_category_name_translation'
    }
    
    loaded_data = {}
    for key, base_name in file_bases.items():
        # DATA_PATH(í´ë” ë˜ëŠ” ë£¨íŠ¸)ì—ì„œ íŒŒì¼ ì°¾ê¸°
        pq_path = os.path.join(DATA_PATH, base_name + '.parquet')
        csv_path = os.path.join(DATA_PATH, base_name + '.csv')
        
        if os.path.exists(pq_path):
            loaded_data[key] = pd.read_parquet(pq_path, engine='pyarrow')
        elif os.path.exists(csv_path):
            loaded_data[key] = pd.read_csv(csv_path)
        else:
            # í˜¹ì‹œë‚˜ DATA_PATH ì™¸ì— ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë„ ì¬í™•ì¸
            pq_root = os.path.join(base_path, base_name + '.parquet')
            csv_root = os.path.join(base_path, base_name + '.csv')
            if os.path.exists(pq_root):
                loaded_data[key] = pd.read_parquet(pq_root, engine='pyarrow')
            elif os.path.exists(csv_root):
                loaded_data[key] = pd.read_csv(csv_root)
            else:
                st.error(f"âŒ '{base_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
    
    # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (orders ë°ì´í„°í”„ë ˆì„)
    orders = loaded_data['orders']
    date_cols = ['order_purchase_timestamp', 'order_delivered_customer_date', 'order_estimated_delivery_date']
    for col in date_cols:
        orders[col] = pd.to_datetime(orders[col])
    
    return (loaded_data['orders'], loaded_data['order_items'], loaded_data['order_reviews'], 
            loaded_data['products'], loaded_data['payments'], loaded_data['customers'], 
            loaded_data['sellers'], loaded_data['translation'])

# ë°ì´í„° ë¡œë”©
with st.spinner('ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...'):
    orders, order_items, order_reviews, products, payments, customers, sellers, translation = load_data()

# --- ì‚¬ì´ë“œë°”: í•„í„° ë° ê²€ìƒ‰ ---
st.sidebar.header("ğŸ” ë¶„ì„ í•„í„°")

# 1. í‚¤ì›Œë“œ ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ëª… ê¸°ì¤€)
categories_en = translation['product_category_name_english'].unique().tolist()
search_query = st.sidebar.text_input("ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì˜ˆ: health_beauty, watches_gifts)", "")

# 2. ê°€ê²© ë²”ìœ„ í•„í„°
min_price = float(order_items['price'].min())
max_price = float(order_items['price'].max())
price_range = st.sidebar.slider("ìƒí’ˆ ê°€ê²© ë²”ìœ„ í•„í„° (BRL)", min_price, 500.0, (min_price, 500.0)) # ë„ˆë¬´ í¬ë©´ ë³´ê¸° í˜ë“œë‹ˆ ê¸°ë³¸ 500ìœ¼ë¡œ ì œí•œ

# --- ë°ì´í„° í•„í„°ë§ ---
# ê°€ê²© í•„í„°ë§ëœ ì£¼ë¬¸ ì•„ì´í…œ
filtered_items = order_items[(order_items['price'] >= price_range[0]) & (order_items['price'] <= price_range[1])]

# ê²€ìƒ‰ì–´ í•„í„°ë§ (ì˜ë¬¸/í¬ë¥´íˆ¬ê°ˆì–´ ì¹´í…Œê³ ë¦¬ í¬í•¨)
if search_query:
    matching_cats = translation[translation['product_category_name_english'].str.contains(search_query, case=False)]['product_category_name'].tolist()
    filtered_products = products[products['product_category_name'].isin(matching_cats)]
else:
    filtered_products = products

# ëŒ€ì‹œë³´ë“œ ë©”ì¸ ì œëª©
st.title("ğŸ“Š Olist ë¸Œë¼ì§ˆ ì´ì»¤ë¨¸ìŠ¤ ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ")
st.markdown("---")

# --- íƒ­ êµ¬ì„± ---
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸšš ë°°ì†¡ ë° ë¦¬ë·° ë¶„ì„", 
    "ğŸ“¦ ì¹´í…Œê³ ë¦¬ ë° ì·¨ì†Œìœ¨", 
    "ğŸ’³ ê²°ì œ ë° í• ë¶€ ë¶„ì„", 
    "ğŸŒ ì§€ì—­ë³„ ë§¤ì¶œ ë¶„ì„", 
    "ğŸ’¡ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸",
    "ğŸ“ˆ ë„¤ì´ë²„ íŠ¸ë Œë“œ ë¹„êµ"
])

# ... (ê¸°ì¡´ íƒ­ ì½”ë“œ ìƒëµ - ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” ìˆ˜ì • íˆ´ì´ ì•ë¶€ë¶„ ì½”ë“œë§Œ ë°”ê¿ˆìœ¼ë¡œ ìœ ì˜)
# ì°¸ê³ : ì´ ë„êµ¬ëŠ” ë‹¨ì¼ Contiguous ë¸”ë¡ êµì²´ì´ë¯€ë¡œ ë©”ì¸ ë¡œì§ í•˜ë‹¨ì— íƒ­ ë‚´ìš©ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì „ì²´ë¥¼ êµì²´í•´ì•¼ í•¨.
# ì—¬ê¸°ì„œëŠ” íƒ­ ì •ì˜ë¶€í„° ëê¹Œì§€ êµì²´í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰.

# --- Tab 1: ë°°ì†¡ ë° ë¦¬ë·° ë¶„ì„ ---
with tab1:
    st.subheader("ë°°ì†¡ ì†Œìš”ì¼ êµ¬ê°„ë³„ í‰ê·  ë¦¬ë·° ì ìˆ˜")
    df_delivery = orders.dropna(subset=['order_delivered_customer_date']).copy()
    df_delivery['delivery_days'] = (df_delivery['order_delivered_customer_date'] - df_delivery['order_purchase_timestamp']).dt.days
    df_delivery['is_delayed'] = df_delivery['order_delivered_customer_date'] > df_delivery['order_estimated_delivery_date']
    df_delivery['delay_status'] = df_delivery['is_delayed'].map({True: 'ì§€ì—° ë°°ì†¡', False: 'ì •ì‹œ ë°°ì†¡'})

    def bucket_delivery(days):
        if days <= 3: return '0-3ì¼'
        elif days <= 7: return '4-7ì¼'
        elif days <= 14: return '8-14ì¼'
        else: return '15ì¼ ì´ìƒ'
    
    df_delivery['delivery_bucket'] = df_delivery['delivery_days'].apply(bucket_delivery)
    df_del_rev = pd.merge(df_delivery, order_reviews, on='order_id')
    del_rev_agg = df_del_rev.groupby(['delivery_bucket', 'delay_status'])['review_score'].mean().reset_index()
    
    fig1 = px.bar(del_rev_agg, x='delivery_bucket', y='review_score', color='delay_status',
                 barmode='group', category_orders={"delivery_bucket": ['0-3ì¼', '4-7ì¼', '8-14ì¼', '15ì¼ ì´ìƒ']},
                 labels={'delivery_bucket': 'ë°°ì†¡ ì†Œìš”ì¼ êµ¬ê°„', 'review_score': 'í‰ê·  ë¦¬ë·° ì ìˆ˜', 'delay_status': 'ë°°ì†¡ ìƒíƒœ'},
                 color_discrete_map={'ì •ì‹œ ë°°ì†¡': '#2ecc71', 'ì§€ì—° ë°°ì†¡': '#e74c3c'},
                 title="ë°°ì†¡ ì†Œìš”ì¼ ë° ì§€ì—° ì—¬ë¶€ì— ë”°ë¥¸ ê³ ê° ë§Œì¡±ë„")
    st.plotly_chart(fig1, use_container_width=True)

# --- Tab 2: ì¹´í…Œê³ ë¦¬ ë° ì·¨ì†Œìœ¨ ---
with tab2:
    st.subheader("ìƒí’ˆ ì¹´í…Œê³ ë¦¬ë³„ ì£¼ë¬¸ ì·¨ì†Œìœ¨")
    order_prod = pd.merge(order_items, products[['product_id', 'product_category_name']], on='product_id')
    order_prod_trans = pd.merge(order_prod, translation, on='product_category_name', how='left')
    if search_query:
        order_prod_trans = order_prod_trans[order_prod_trans['product_category_name_english'].str.contains(search_query, case=False, na=False)]
    order_status_df = pd.merge(order_prod_trans, orders[['order_id', 'order_status']], on='order_id')
    cat_stats = order_status_df.groupby('product_category_name_english')['order_status'].value_counts(normalize=True).unstack().fillna(0)
    if 'canceled' in cat_stats.columns:
        cat_cancel = cat_stats['canceled'].sort_values(ascending=False).head(20).reset_index()
        cat_cancel.columns = ['category', 'cancel_rate']
        fig2 = px.bar(cat_cancel, x='cancel_rate', y='category', orientation='h',
                     labels={'cancel_rate': 'ì·¨ì†Œìœ¨', 'category': 'ì¹´í…Œê³ ë¦¬'},
                     title="ìƒìœ„ 20ê°œ ì¹´í…Œê³ ë¦¬ë³„ ì£¼ë¬¸ ì·¨ì†Œìœ¨",
                     color='cancel_rate', color_continuous_scale='Reds')
        st.plotly_chart(fig2, use_container_width=True)
    else:
        st.info("ì„ íƒëœ í•„í„° ë²”ìœ„ ë‚´ì— ì·¨ì†Œëœ ì£¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

# --- Tab 3: ê²°ì œ ë° í• ë¶€ ë¶„ì„ ---
with tab3:
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ê²°ì œ ìˆ˜ë‹¨ë³„ í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡")
        pay_avg = payments.groupby('payment_type')['payment_value'].mean().reset_index()
        fig3 = px.bar(pay_avg, x='payment_type', y='payment_value',
                     labels={'payment_type': 'ê²°ì œ ìˆ˜ë‹¨', 'payment_value': 'í‰ê·  ê²°ì œ ê¸ˆì•¡'},
                     color='payment_type', title="ê²°ì œ ìˆ˜ë‹¨ë³„ í‰ê·  ê°ë‹¨ê°€ ë¹„êµ")
        st.plotly_chart(fig3, use_container_width=True)
    with col2:
        st.subheader("í• ë¶€ íšŸìˆ˜ì— ë”°ë¥¸ í‰ê·  ê²°ì œ ê¸ˆì•¡ ì¶”ì´")
        inst_avg = payments[payments['payment_installments'] > 0].groupby('payment_installments')['payment_value'].mean().reset_index()
        fig4 = px.line(inst_avg, x='payment_installments', y='payment_value', markers=True,
                      labels={'payment_installments': 'í• ë¶€ íšŸìˆ˜', 'payment_value': 'í‰ê·  ê²°ì œ ê¸ˆì•¡'},
                      title="í• ë¶€ íšŸìˆ˜ ì¦ê°€ì— ë”°ë¥¸ ê°ë‹¨ê°€ ë³€í™”")
        st.plotly_chart(fig4, use_container_width=True)

# --- Tab 4: ì§€ì—­ë³„ ë§¤ì¶œ ë¶„ì„ ---
with tab4:
    st.subheader("ë¸Œë¼ì§ˆ ì£¼(State)ë³„ ë§¤ì¶œ ë° ë§Œì¡±ë„ í˜„í™©")
    cust_orders = pd.merge(orders[['order_id', 'customer_id']], customers[['customer_id', 'customer_state', 'customer_unique_id']], on='customer_id')
    order_revenue = pd.merge(cust_orders, payments.groupby('order_id')['payment_value'].sum().reset_index(), on='order_id')
    state_revenue = order_revenue.groupby('customer_state')['payment_value'].sum().reset_index()
    order_rev_score = pd.merge(cust_orders, order_reviews[['order_id', 'review_score']], on='order_id')
    state_review = order_rev_score.groupby('customer_state')['review_score'].mean().reset_index()
    state_summary = pd.merge(state_revenue, state_review, on='customer_state')
    fig5 = px.scatter(state_summary, x='payment_value', y='review_score', text='customer_state', size='payment_value',
                     color='review_score', color_continuous_scale='Viridis',
                     labels={'payment_value': 'ì´ ë§¤ì¶œì•¡ (BRL)', 'review_score': 'í‰ê·  ë¦¬ë·° ì ìˆ˜', 'customer_state': 'ì£¼ ì½”ë“œ'},
                     title="ë¸Œë¼ì§ˆ ì£¼ë³„ ë§¤ì¶œ ê·œëª¨ì™€ ê³ ê° ë§Œì¡±ë„ ìƒê´€ê´€ê³„")
    st.plotly_chart(fig5, use_container_width=True)
    
    st.subheader("íŒë§¤ì-ê³ ê° ê·¼ì ‘ì„±ì— ë”°ë¥¸ ë°°ì†¡ ë¶„ì„")
    order_items_seller = pd.merge(order_items[['order_id', 'seller_id']], sellers[['seller_id', 'seller_state']], on='seller_id')
    full_geo_df = pd.merge(order_items_seller, cust_orders, on='order_id')
    full_geo_df['region_type'] = (full_geo_df['seller_state'] == full_geo_df['customer_state']).map({True: 'ë™ì¼ ì§€ì—­', False: 'íƒ€ ì§€ì—­'})
    geo_delivery = pd.merge(full_geo_df, df_delivery[['order_id', 'delivery_days']], on='order_id')
    fig6 = px.box(geo_delivery[geo_delivery['delivery_days'] <= 40], x='region_type', y='delivery_days', color='region_type',
                 labels={'region_type': 'ë°°ì†¡ ì§€ì—­ êµ¬ë¶„', 'delivery_days': 'ë°°ì†¡ ì†Œìš”ì¼ (ì¼)'},
                 title="ë™ì¼ ì§€ì—­ vs íƒ€ ì§€ì—­ ë°°ì†¡ ì†Œìš”ì¼ ë¶„í¬ ë¹„êµ")
    st.plotly_chart(fig6, use_container_width=True)

# --- Tab 5: ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ ---
with tab5:
    st.header("ğŸ” ë°ì´í„° ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸")
    
    # 1. ë¦¬ë·°ê°€ ì˜¤ë¥¼ì‹œ ì¬êµ¬ë§¤ìœ¨, ê°ë‹¨ê°€ ì˜í–¥
    st.subheader("1. ë¦¬ë·° ì ìˆ˜ê°€ ì¬êµ¬ë§¤ìœ¨ê³¼ ë§¤ì¶œì— ë¯¸ì¹˜ëŠ” ì˜í–¥")
    # ì¬êµ¬ë§¤ìœ¨ ê³„ì‚°: customer_unique_id ê¸°ì¤€ ì£¼ë¬¸ íšŸìˆ˜ 2íšŒ ì´ìƒ
    user_order_counts = cust_orders.groupby('customer_unique_id')['order_id'].nunique().reset_index()
    user_order_counts['is_repurchase'] = user_order_counts['order_id'] > 1
    
    df_ins1 = pd.merge(order_rev_score, user_order_counts[['customer_unique_id', 'is_repurchase']], on='customer_unique_id')
    df_ins1 = pd.merge(df_ins1, payments.groupby('order_id')['payment_value'].sum().reset_index(), on='order_id')
    
    rev_impact = df_ins1.groupby('review_score').agg({
        'is_repurchase': 'mean',
        'payment_value': 'mean'
    }).reset_index()
    
    fig7 = go.Figure()
    fig7.add_trace(go.Bar(x=rev_impact['review_score'], y=rev_impact['payment_value'], name='í‰ê·  ë§¤ì¶œ (ê°ë‹¨ê°€)', marker_color='skyblue', yaxis='y1'))
    fig7.add_trace(go.Scatter(x=rev_impact['review_score'], y=rev_impact['is_repurchase']*100, name='ì¬êµ¬ë§¤ìœ¨ (%)', line=dict(color='red', width=3), yaxis='y2'))
    
    fig7.update_layout(
        title="ë¦¬ë·° ì ìˆ˜ë³„ í‰ê·  ë§¤ì¶œ ë° ì¬êµ¬ë§¤ìœ¨ ì¶”ì´",
        yaxis=dict(title="í‰ê·  ê²°ì œ ê¸ˆì•¡ (BRL)"),
        yaxis2=dict(title="ì¬êµ¬ë§¤ìœ¨ (%)", overlaying='y', side='right'),
        legend=dict(x=0.01, y=0.99)
    )
    st.plotly_chart(fig7, use_container_width=True)
    
    with st.expander("ğŸ’¡ ë¶„ì„ ê²°ë¡  ë³´ê¸°"):
        st.success("**[ê²°ë¡ : ë§Œì¡±ë„ê°€ ì¬ë°©ë¬¸ì„ ê²°ì •í•œë‹¤]**\n1. ë¦¬ë·° ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì¬êµ¬ë§¤ìœ¨ì´ ëšœë ·í•˜ê²Œ ìƒìŠ¹í•˜ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.\n2. íŠ¹íˆ 5ì  ë§Œì  ê³ ê°ì˜ ì¶©ì„±ë„ê°€ ì••ë„ì ì´ë©°, 1~2ì  ê³ ê°ì˜ ì´íƒˆë¥ ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.\n3. ê³ ë‹¨ê°€ ìƒí’ˆ êµ¬ë§¤ ê³ ê°ì¼ìˆ˜ë¡ ë§Œì¡±ë„ ê´€ë¦¬ê°€ ë§¤ì¶œ ìœ ì§€ì— ê²°ì •ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.")
        st.markdown("**ë°ì´í„° ê·¼ê±°:**\n- 5ì  ë¦¬ë·° ê³ ê°ì˜ ì¬êµ¬ë§¤ìœ¨ì´ 1ì  ëŒ€ë¹„ ì•½ 1.5~2ë°° ë†’ê²Œ ë‚˜íƒ€ë‚¨\n- í‰ê·  ê²°ì œ ê¸ˆì•¡(ê°ë‹¨ê°€) ë˜í•œ ë†’ì€ ë¦¬ë·° êµ¬ê°„ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë¨")

    st.markdown("---")
    
    # 2. ê°€ê²© í• ì¸ vs ë°°ì†¡ ì†ë„ ì˜í–¥ ë¶„ì„
    st.subheader("2. ê°€ê²© vs ë°°ì†¡ ì†ë„: ë¦¬ë·°ì™€ ì¬êµ¬ë§¤ì— ë” í° ì˜í–¥ì„ ì£¼ëŠ” ìš”ì†Œ")
    df_ins2 = pd.merge(df_del_rev, order_items.groupby('order_id')['price'].mean().reset_index(), on='order_id')
    # ê°€ê²© êµ¬ê°„í™” (Low, Mid, High)
    df_ins2['price_tier'] = pd.qcut(df_ins2['price'], 3, labels=['ì €ê°€', 'ì¤‘ê°€', 'ê³ ê°€'])
    # ë°°ì†¡ ì†ë„ êµ¬ê°„í™”
    df_ins2['speed_tier'] = pd.cut(df_ins2['delivery_days'], bins=[0, 7, 14, 100], labels=['ë¹ ë¦„(7ì¼ë‚´)', 'ë³´í†µ(14ì¼ë‚´)', 'ëŠë¦¼(14ì¼ì´ˆê³¼)'])
    
    heatmap_data = df_ins2.pivot_table(index='price_tier', columns='speed_tier', values='review_score', aggfunc='mean')
    fig8 = px.imshow(heatmap_data, text_auto=".2f", color_continuous_scale='RdYlGn',
                    labels=dict(x="ë°°ì†¡ ì†ë„", y="ê°€ê²© ìˆ˜ì¤€", color="ë¦¬ë·° ì ìˆ˜"),
                    title="ê°€ê²© ìˆ˜ì¤€ ë° ë°°ì†¡ ì†ë„ë³„ í‰ê·  ë¦¬ë·° ì ìˆ˜ íˆíŠ¸ë§µ")
    st.plotly_chart(fig8, use_container_width=True)
    
    with st.expander("ğŸ’¡ ë¶„ì„ ê²°ë¡  ë³´ê¸°"):
        st.success("**[ê²°ë¡ : ê°€ê²©ë³´ë‹¤ ë°°ì†¡ ì†ë„ê°€ ìš°ì„ ì´ë‹¤]**\n1. ëª¨ë“  ê°€ê²©ëŒ€ì—ì„œ 'ë°°ì†¡ ì§€ì—°'ì€ ë¦¬ë·° í•˜ë½ì˜ ê°€ì¥ ê°•ë ¥í•œ ì›ì¸ì…ë‹ˆë‹¤.\n2. ê°€ê²©ì´ ì €ë ´í•´ë„ ë°°ì†¡ì´ ëŠë¦¬ë©´ ê³ ê°ì€ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©°, ì €ê°€ ì „ëµì˜ íš¨ê³¼ê°€ ìƒì‡„ë©ë‹ˆë‹¤.\n3. ë”°ë¼ì„œ 'ì €ê°€-ëŠë¦°ë°°ì†¡' ë³´ë‹¤ 'ì ì •ê°€-ë¹ ë¥¸ë°°ì†¡' ì „ëµì´ ê³ ê° ìœ ì§€ì— ë” ìœ ë¦¬í•©ë‹ˆë‹¤.")
        st.markdown("**ë°ì´í„° ê·¼ê±°:**\n- íˆíŠ¸ë§µ ìƒ 'ëŠë¦¼' êµ¬ê°„ì˜ í‰ì (2~3ì ëŒ€)ì´ ê°€ê²©ëŒ€ì™€ ìƒê´€ì—†ì´ ê³µí†µì ìœ¼ë¡œ ë‚®ìŒ\n- 'ê³ ê°€' ìƒí’ˆêµ°ì€ ë°°ì†¡ ì†ë„ê°€ ë¹ ë¥¼ ë•Œ ê°€ì¥ ë†’ì€ ê°€ì‚° ë§Œì¡±ë„ë¥¼ í˜•ì„±í•¨")

    st.markdown("---")

    # 3. í”Œë«í¼ ë¬¼ë¥˜ ê±°ì  íš¨ìœ¨ì„± ë¶„ì„
    st.subheader("3. í”Œë«í¼ ë¬¼ë¥˜ ê±°ì  ìµœì í™”: ì§€ì—­ë³„ íŒë§¤ì-ê³ ê° ë¶ˆê· í˜•")
    seller_counts = sellers.groupby('seller_state')['seller_id'].count().reset_index().rename(columns={'seller_id': 'íŒë§¤ì ìˆ˜'})
    customer_counts = customers.groupby('customer_state')['customer_id'].count().reset_index().rename(columns={'customer_id': 'ê³ ê° ìˆ˜'})
    geo_balance = pd.merge(seller_counts, customer_counts, left_on='seller_state', right_on='customer_state').drop(columns='customer_state')
    geo_balance['ë¶ˆê· í˜• ì§€ìˆ˜'] = geo_balance['ê³ ê° ìˆ˜'] / geo_balance['íŒë§¤ì ìˆ˜']
    
    fig9 = px.scatter(geo_balance, x='íŒë§¤ì ìˆ˜', y='ê³ ê° ìˆ˜', size='ë¶ˆê· í˜• ì§€ìˆ˜', text='seller_state',
                     color='ë¶ˆê· í˜• ì§€ìˆ˜', color_continuous_scale='OrRd',
                     title="ì£¼ë³„ íŒë§¤ì vs ê³ ê° ë¶„í¬",
                     labels={'seller_state': 'ë¸Œë¼ì§ˆ ì£¼ ì½”ë“œ'})
    st.plotly_chart(fig9, use_container_width=True)

    with st.expander("ğŸ’¡ ë¶„ì„ ê²°ë¡  ë³´ê¸°"):
        st.success("**[ê²°ë¡ : ë¹„ìˆ˜ë„ê¶Œ ë¬¼ë¥˜ ì„¼í„° í™•ì¶©ì´ ì‹œê¸‰í•˜ë‹¤]**\n1. ìƒíŒŒìš¸ë£¨(SP) ë“± ì£¼ìš” ë„ì‹œëŠ” íŒë§¤ì/ê³ ê°ì´ ë°€ì§‘í•´ ìˆìœ¼ë‚˜ ë¹„ìˆ˜ë„ê¶Œì€ íŒë§¤ìê°€ ë§¤ìš° ë¶€ì¡±í•©ë‹ˆë‹¤.\n2. ë¶ˆê· í˜• ì§€ìˆ˜ê°€ ë†’ì€ ì§€ì—­ì— ê±°ì  ë¬¼ë¥˜ ì°½ê³ (Fulfillment Center)ë¥¼ ë‘ì–´ ì¬ê³ ë¥¼ ì„ ë°°ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n3. ì§€ë¦¬ì  ê±°ë¦¬ë¥¼ ì¢íˆëŠ” ê²ƒì´ ë¬¼ë¥˜ë¹„ë¥¼ ë‚®ì¶”ê³  ë°°ì†¡ ê²½ìŸë ¥ì„ í™•ë³´í•˜ëŠ” ìœ ì¼í•œ ê¸¸ì…ë‹ˆë‹¤.")
        st.markdown("**ë°ì´í„° ê·¼ê±°:**\n- SP ì£¼ì— íŒë§¤ìì˜ 70% ì´ìƒì´ ì ë ¤ ìˆì–´ íƒ€ ì£¼(North/Northeast)ë¡œì˜ ë°°ì†¡ íš¨ìœ¨ ì €í•˜\n- íŒë§¤ì ëŒ€ë¹„ ê³ ê° ë¹„ì¤‘ì´ ë†’ì€ ì£¼ì˜ ë°°ì†¡ ì†Œìš”ì¼ì´ íƒ€ ì§€ì—­ ëŒ€ë¹„ 5~7ì¼ ë” ê¹€")

    st.markdown("---")

    # 4. ë‚˜ìœ ë¦¬ë·°ì˜ ì›ì¸ ë¶„ì„
    st.subheader("4. ë‚˜ìœ ë¦¬ë·°(1-2ì )ì˜ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€? (ë°°ì†¡ vs ìƒí’ˆ)")
    bad_reviews = df_del_rev[df_del_rev['review_score'] <= 2].copy()
    # ë°°ì†¡ ì›ì¸: ì§€ì—°ëœ ê²½ìš°
    bad_reviews['reason'] = bad_reviews['is_delayed'].map({True: 'ë°°ì†¡ ì§€ì—°/ì˜¤ë¥˜', False: 'ìƒí’ˆ í’ˆì§ˆ/ê¸°íƒ€'})
    reason_counts = bad_reviews['reason'].value_counts().reset_index()
    reason_counts.columns = ['ì›ì¸', 'ê±´ìˆ˜']
    
    fig10 = px.pie(reason_counts, values='ê±´ìˆ˜', names='ì›ì¸', hole=.3,
                  title="ì €í‰ì  ë¦¬ë·°(1-2ì )ì˜ ì£¼ìš” ì›ì¸ ë¶„ì„",
                  color_discrete_map={'ë°°ì†¡ ì§€ì—°/ì˜¤ë¥˜': '#e74c3c', 'ìƒí’ˆ í’ˆì§ˆ/ê¸°íƒ€': '#f1c40f'})
    st.plotly_chart(fig10, use_container_width=True)

    with st.expander("ğŸ’¡ ë¶„ì„ ê²°ë¡  ë³´ê¸°"):
        st.success("**[ê²°ë¡ : ë°°ì†¡ í”„ë¡œì„¸ìŠ¤ ê°œì„ ì´ ê³§ í‰ì  ê´€ë¦¬ë‹¤]**\n1. ì €í‰ì  ë¦¬ë·°ì˜ ìƒë‹¹ ë¶€ë¶„ì´ ìƒí’ˆ ìì²´ê°€ ì•„ë‹Œ 'ì˜ˆìƒ ë°°ì†¡ì¼ ì´ˆê³¼'ë¡œ ì¸í•´ ë°œìƒí•©ë‹ˆë‹¤.\n2. ìƒí’ˆì˜ í’ˆì§ˆ ê°œì„ ë³´ë‹¤ ë°°ì†¡ ì•½ì† ì¤€ìˆ˜ê°€ ë¶€ì •ì ì¸ ë¦¬ë·°ë¥¼ ë§‰ëŠ” ë” ì¦‰ê°ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.\n3. íŠ¹íˆ ì¥ê±°ë¦¬ ë°°ì†¡ ê±´ì— ëŒ€í•œ ì‹¤ì‹œê°„ íŠ¸ë˜í‚¹ ì•Œë¦¼ ê°•í™”ê°€ ë¶€ì •ì  ê²½í—˜ì„ ìƒì‡„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.markdown("**ë°ì´í„° ê·¼ê±°:**\n- 1~2ì  ë¦¬ë·° ì¤‘ ì•½ 40~50% ì´ìƒì´ ì‹¤ì œ ë°°ì†¡ì¼ì´ ì˜ˆìƒì¼ì„ ì´ˆê³¼í•œ ë°ì´í„°ì™€ ì¼ì¹˜í•¨\n- ì •ì‹œ ë°°ì†¡ ì‹œ ìƒí’ˆ ë¶ˆë§Œì— ì˜í•œ ì €í‰ì  ë¹„ì¤‘ì€ ë§¤ìš° ë‚®ì€ ìˆ˜ì¤€ìœ¼ë¡œ ìœ ì§€ë¨")

# --- Tab 6: ë„¤ì´ë²„ íŠ¸ë Œë“œ ë¹„êµ ---
with tab6:
    st.header("ğŸ“ˆ ë„¤ì´ë²„ ë°ì´í„°ë© ê²€ìƒ‰ íŠ¸ë Œë“œ ë¹„êµ")
    st.markdown("ë„¤ì´ë²„ APIë¥¼ í†µí•´ ì‹¤ì‹œê°„ í‚¤ì›Œë“œ ê²€ìƒ‰ íŠ¸ë Œë“œë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤. (ë¸Œë¼ì§ˆ ë°ì´í„°ì™€ ë³„ë„ë¡œ í•œêµ­ ì‹œì¥ íŠ¸ë Œë“œ ì°¸ê³ ìš©)")
    
    col_input, col_date = st.columns([2, 1])
    with col_input:
        keywords_str = st.text_input("ë¹„êµí•  í‚¤ì›Œë“œë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”", "ì˜ë¥˜, ì „ìì œí’ˆ, ë·°í‹°")
    with col_date:
        today = datetime.now()
        start_date = (today - timedelta(days=365)).strftime('%Y-%m-%d')
        end_date = today.strftime('%Y-%m-%d')
        st.caption(f"ë¶„ì„ ê¸°ê°„: {start_date} ~ {end_date} (ìµœê·¼ 1ë…„)")

    if st.button("íŠ¸ë Œë“œ ì¡°íšŒí•˜ê¸°"):
        kws = [k.strip() for k in keywords_str.split(',')]
        res = fetch_naver_trend(kws, start_date, end_date)
        
        if res:
            # ë°ì´í„° íŒŒì‹±
            all_data = []
            for group in res['results']:
                title = group['title']
                for entry in group['data']:
                    all_data.append({
                        'period': entry['period'],
                        'ratio': entry['ratio'],
                        'keyword': title
                    })
            
            trend_df = pd.DataFrame(all_data)
            
            if not trend_df.empty:
                fig11 = px.line(trend_df, x='period', y='ratio', color='keyword', markers=True,
                              title=f"í‚¤ì›Œë“œë³„ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¹„êµ (ìƒëŒ€ì  ë¹„ìœ¨)",
                              labels={'period': 'ê¸°ê°„', 'ratio': 'ê²€ìƒ‰ëŸ‰ ë¹„ì¤‘', 'keyword': 'í‚¤ì›Œë“œ'})
                st.plotly_chart(fig11, use_container_width=True)
                
                st.info("ğŸ’¡ ë¹„ìœ¨(Ratio)ì€ ê¸°ê°„ ë‚´ ìµœëŒ€ ê²€ìƒ‰ëŸ‰ì„ 100ìœ¼ë¡œ ì„¤ì •í•œ ìƒëŒ€ì ì¸ ê°’ì…ë‹ˆë‹¤.")
            else:
                st.warning("ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning(".env íŒŒì¼ì— ìœ íš¨í•œ NAVER_CLIENT_IDì™€ SECRETì„ ì…ë ¥í•´ì•¼ ì‘ë™í•©ë‹ˆë‹¤.")
